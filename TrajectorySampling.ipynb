{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Environment:\n",
    "    def __init__(self, num_states = 1000, branching_factor = 10):\n",
    "        self.num_states = num_states\n",
    "        self.branching_factor = branching_factor\n",
    "        self.transitions1 = [np.random.choice(num_states, branching_factor, replace=False) for _ in range(num_states)]\n",
    "        self.transitions2 = [np.random.choice(num_states, branching_factor, replace=False) for _ in range(num_states)]\n",
    "        self.num_actions = 2\n",
    "        self.reset_state()\n",
    "        self.eps = 0.1\n",
    "        \n",
    "    def reset_state(self):\n",
    "        self.state = 0\n",
    "        \n",
    "    def step(self, action):\n",
    "        done = False\n",
    "        idx = np.random.choice(self.branching_factor)\n",
    "        if action == 0:\n",
    "            self.state = self.transitions1[self.state][idx]\n",
    "        else:\n",
    "            self.state = self.transitions2[self.state][idx]\n",
    "            \n",
    "        if self.eps <= np.random.uniform(0, 1):\n",
    "            done = True\n",
    "            \n",
    "        reward = np.random.normal(0, 1)\n",
    "        return self.state, idx, reward, done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlanningAgent:\n",
    "    def __init__(self, num_states = 1000, branching_factor = 10):\n",
    "        self.num_actions = 2\n",
    "        self.model = np.zeros((num_states, self.num_actions, branching_factor, 2))\n",
    "        self.Q = np.zeros((num_states, self.num_actions))\n",
    "        self.branching_factor = branching_factor\n",
    "        \n",
    "    def get_action(self, state, eps=0.1):\n",
    "        if eps <= np.random.uniform(0, 1):\n",
    "            action = np.random.choice(self.num_actions)\n",
    "        else:\n",
    "            action = np.argmax(self.Q[state, ])\n",
    "        return action\n",
    "    \n",
    "    def update_model(self, state, action, new_state_idx, reward):\n",
    "        \"\"\"\n",
    "        Model keeps track of mean.\n",
    "        \"\"\"\n",
    "        self.model[state, action, new_state_idx, 0] += 1\n",
    "        k = self.model[state, action, new_state_idx, 0]\n",
    "        self.model[state, action, new_state_idx, 1] += 1./k * (reward - self.model[state, action, new_state_idx, 1])\n",
    "        \n",
    "    def sample_model(self, state, action):\n",
    "        new_state_idx = np.random.choice(self.branching_factor)\n",
    "        mu = self.model[state, action, new_state_idx, 1]\n",
    "        reward = np.random.normal(mu)\n",
    "        return new_state_idx, reward\n",
    "    \n",
    "    def update_Q(self, state, action, new_state_idx, reward):\n",
    "        self.Q[state, action] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
